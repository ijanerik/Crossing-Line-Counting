\chapter{Datasets}
In this chapter we explain the datasets in more depth. First we explain the requirements of the dataset to correctly train and evaluate each dataset. To compensate for lack of some required labelling a tool is written and explained. Lastly all the datasets are explained in more depth.

\section{Requirements}
For training and evaluation we need two different methods of labelling. For the density map generation the position of each pedestrian is required for the frames which are used for training. For evaluation the line crossing it is required to label the amount of pedestrians crossing the LOI from each side. Ideally the training set is purely labeled with head-tags and the evaluation set only with line crossing labelling.

\section{Labelling}
\begin{figure}[!htb]
\centering
\includegraphics[width=0.6\textwidth]{images/labeller}
\caption{User interface of the labeller}
\label{fig:labeller}
\end{figure}

Several Crowd Counting datasets provide sequences of frames with corresponding pedestrian labelling. However most of those datasets don't provide line crossing labelling. Therefore I build a tool to label videos for line crossing (Figure \ref{fig:labeller}).
The labeller loads a video from the unlabeled videos. In this video the user can label multiple lines by first clicking on the video to draw a line and afterwards fill in the amount of pedestrians crossing the line during the video. Additionally the user can scroll and view through the video using multiple manipulations.


\section{Datasets}
\begin{figure}[h]
\centering
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{images/dataset_tub}
  \caption{TUB}
  \label{fig:dataset_ucsd}
\end{subfigure}%
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{images/dataset_fudan}
  \caption{Fudan-ShanghaiTech}
  \label{fig:dataset_fudan}
\end{subfigure}%
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{images/dataset_aicity}
  \caption{AI City Challenge}
  \label{fig:dataset_aicity}
\end{subfigure}%
\caption{Samples of each dataset}
\label{fig:datasets}
\end{figure}

\subsection{Fudan-ShanghaiTech}
The Fudan ShanghaiTech dataset \cite{Fang2019} is a public dataset with 100 videos of 13 different scenes. Each video contains 6 seconds of footage at 25 fps and have a resolution of 1920x1080 or 1280x720 (Sample of scene in figure \ref{fig:dataset_fudan}). The scenes have between 20-100 pedestrians per frame. In each frame the pedestrians in the frame are labeled with a bounding-box and a center-point of the bounding-box. The dataset contains 60 training videos and 40 testing videos.

The lack of trajectories and custom line crossing labelling requires the use of the custom build labeller (Figure \ref{fig:labeller}). This is done on the 40 videos of the test set.

\subsection{AI City Challenge}
The AI City Challenge dataset is a huge dataset of cars crossing on a road. The total dataset contains 20 different scenes, but only the four busiest scenes are used for training and testing. Each scene contains 3.5 minutes of footage in 10FPS, where the first half of the scene is used as training and the second half for testing. Each vehicle is labeled as a bounding box, which can be used for the centre-point. Additionally a trajectory of each vehicle is provided, which will be used to create the Line of Interest labelling. So no extra labelling for this dataset is required. ww

\subsection{CrowdFlow}
CrowdFlow is a synthetic dataset generated using the game engine Unreal. The dataset contains 5 scenes with each a sequence with a panning camera and a fixed camera. For the experiments only 5 sequences with the fixed camera are used. Each sequences has a duration of 12.5 seconds at a FPS of 25. The CrowdFlow dataset sequences contain a large amount of pedestrians ranging between 200-1000. For each pedestrian the position and trajectory is labeled. 

For each sequence 3 lines are drawn. By utilizing the present trajectory, for each line the crossed pedestrians can be counted, these crosses range between 20 and 150 per line.

Due to the sparsity of the data only 20\% of the data (10\% at the start and 10\% at the end of the sequence) is used for training and the rest is used as testing.

During testing it appeared that the last sequence (IM05) contains errors in the labeling. Therefore the last sequences is discarded, so in total 4 sequences are used for this dataset.