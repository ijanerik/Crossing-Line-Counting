\chapter{Background}
In this chapter a selection of terms is explained which gives a basis to understand the rest of this thesis. This background is created with the assumption that the reader has a basic background in Machine Learning and (Convolutional) Neural Networks.

\section{Crowd Counting}
Crowd Counting in Machine Learning is a hot topic with a lot of new and recent papers. The goal of Crowd Counting is to count the amount of pedestrians present in a given image. This can be an individual image or a frame of a video sequence. The goal with Crowd Counting is only to give the amount of people in the image. The exact location of each pedestrian is irrelevant for this task. Crowd Counting can be done on a whole image or only given a part of the image. This region is then specified as the Region of Interest.

So the goal is to predict based on the given image the amount of pedestrians in an image. So can we directly predict the amount of pedestrians in the frame using a Machine Learning method? With a direct approach the amount of supervision on the weights is very low, so to train the model correctly, the amount of images required is very high. So all recent State-of-the-Art methods make use of an intermediate representation to give the model enough supervision to perform Crowd Counting with a low amount of training samples.

\subsection{Object Recognition}
A simple solution would be found in Object Recognition, as well a subfield of Machine Learning. This tries to locate objects given an image or video. By counting the amount of found objects in a frame we can predict the amount of pedestrians in a frame. For an area with a low count of pedestrians which are large enough, existing object recognition methods would be sufficient to recognize each pedestrian and give the correct count of the pedestrians in the given region.

So why not use general Object Recognition for Crowd Counting? The accuracy of Object Recognition will quickly degrade when pedestrians get smaller and the amount of pedestrians in the frame will increase. A lot of Object Recognition software has limitations with the total amount of objects it can recognize in a single image (Mostly around 50-100). Additionally they have a hard time when objects get occluded by each other, especially when they are small.
\todo{This should be backedup by real numbers/papers. YOLO check limit and some others, maybe other crowd counting papers}
Therefore most of the benchmarks used in Crowd Counting contain several hundred pedestrians to several thousands pedestrians per frame.
\todo{Show the average pedestrians per benchmark to backup numbers}

\subsection{Density Map}
To the best of our knowledge all of the State-of-the-Art methods currently use a density map as extra supervision representation. A density map for Crowd Counting is a map which represents the density of pedestrians of each pixel. The density map is generated by taking the locations of each pedestrian ($x_p$ and $y_p$ in equation \ref{eq:density_pixel}) and create a Gaussian shaped circle around this location with a sum of 1. The amount of pedestrians in the frame can be extracted from the density map by taking the sum over all the pixels of the density map (Equation \ref{eq:density_sum}, where $D_i(x,y)$ is the density for location $x,y$ for trainings frame $i$).

\begin{equation}
\label{eq:density_pixel}
	D_i(x,y) = \frac{1}{2 \pi \sigma_p^2}\sum^P_{p=1} e^{\frac{(x_p-x)^2+(y_p-x)^2}{-2 \sigma_p^2}}
\end{equation}

\begin{equation}
	\label{eq:density_sum}
	C_i = \sum_{x=0,y=0}^{X,Y} D_i(x,y)
\end{equation}

Several methods have been presented to optimize the generation of density maps. For most medium dense frames the difference in methods is minimal. Often in benchmarks with medium dense frames a fixed sigma is used ($\sigma_p=\sigma_i$ in equation \ref{eq:density_pixel}). For highly dense frames the use of different methods can have a difference, especially when the difference in size between close pedestrians and pedestrians in the background is large.
\todo{Show image of crowd and of the density map}

\section{Flow Estimation}


\section{Line of Interest}