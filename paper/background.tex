\chapter{Background}
In this chapter a selection of terms is explained which gives a basis to understand the rest of this thesis. This background is created with the assumption that the reader has a basic background in Machine Learning and (Convolutional) Neural Networks.

\todo{Reframe ROI and LOI in the introduction or in the rest of the paper}
\section{Region of Interest}
The Region of Interest problem is a widely studied problem in which the goal is to estimate the amount of pedestrians given a single image. Directly predicting the counted pedestrians given a Neural Network is a hard task, because of the lack of supervision, this would require a large amount of samples to accurately solve this task. All recent State-of-the-Art methods therefore use an intermediate representation to give the model enough supervision to perform Crowd Counting with a low amount of training samples.

In the early days of Crowd Counting several methods have been proposed which use \emph{detection-based} methods to estimate the amount of pedestrians \cite{Dalal2005, Dollar2012} . Several papers were introduced which tried to detect only the head \cite{Subburaman2012} and others tried to focus on general part detection \cite{Wu2007, Lin2010}. These methods rely on individually detecting the pedestrians. This becomes much harder when occlusion of the pedestrians start to happen. This is why the performance of these methods start to degrade when the density of the pedestrians in an image start to increase.

Later papers introduced a \emph{regression-based} solution, which tries to predict the amount of pedestrians in crowd blobs \cite{Chan2009, Idrees2013, zheng_cross-line_2019}. Using SVM or other regressor methods and several features such as the amount of foregrounds pixels of the blob and detected key points the count inside crowd blobs were predicted. Regression based solutions were an improvement over the detection methods, but still lack the capabilities to estimate pedestrians counts in highly occluded areas.

\subsection{Density Map}

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/example_density_demo}
\caption{Example of generated density map on the right side, for the left image}
\label{fig:density_map}
\end{figure}
With the introduction of Convolutional Neural Networks in the field of Crowd Counting density maps were proposed to count pedestrians \cite{Zhang2016, Liu2019, li2018csrnet}. A \emph{density map} (Figure \ref{fig:density_map}) used for Region of Interest is a map which represents the density of pedestrians of each pixel. The density map is generated by taking the locations of each pedestrian ($p=\begin{bmatrix} x_p \\ y_p \end{bmatrix}$ in equation \ref{eq:density_pixel}) and place those locations on the the density map.

Individual dots are very hard for a Neural Network to detect correctly and are proned to errors. To circumvent this a Gaussian shaped circle is created around the location of the individual, still with with a sum of 1. The amount of pedestrians in the frame can be extracted from the density map by taking the sum over all the pixels of the density map (Equation \ref{eq:density_sum}, where $D_t(p)$ is the density for location $p=\begin{bmatrix} x_p \\ y_p \end{bmatrix}$ for trainings frame $t$).

\begin{equation}
\label{eq:density_pixel}
	D_t(p) = \frac{1}{2 \pi \sigma_p^2}\sum_{p\in P} e^{\frac{(x_p-x)^2+(y_p-x)^2}{-2 \sigma_p^2}}
\end{equation}

\begin{equation}
	\label{eq:density_sum}
	C_t = \sum_{p\in P} D_t(p)
\end{equation}

Early networks for density estimation were mostly multi-column model \cite{Zhang2016}, which use different sizes of filters to detect pedestrians of different sizes. With CSRNet \cite{li2018csrnet} dilation filters were introduced. Dilation filters (Figure \ref{fig:csrnet_dilation}) enlarge the filter area without increasing the amount of parameters. With dilation filters the necessity of using multi-column models was gone.

Other papers focused on improving the performance using extra information \cite{Shi_2018_CVPR, shi2019counting, Liu2019}, such as global density \cite{shi2019counting} and variable Gaussians for density map generation \cite{Zhang2016, li2018csrnet, Wan2019}. A third one is adding motion by doing video-based counting.
\todo{Maybe add more papers??}


\section{Flow Estimation}
The research which is done on the Flow Estimation problem is widely used. Approaches on this topic can be used in a wide range of applications which makes it very interesting. Already in the early 1980's Horn and Schunck \cite{Horn1981} published the first paper which tried to predict flow. Since then lots of different approaches have been published \cite{Memin1998, Bruhn2005, Brox2014}. Long conventional mathematical approaches have ruled the flow estimation field. Later also learnable models were introduced \cite{Pock2008, Wedel2009}.

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{images/example_flow_demo}
\caption{Example of generated velocity map on the right side, for the left image}
\label{fig:flow_map}
\end{figure}


Recent papers however make use of Convolutional Neural Network based models \cite{Dosovitskiy2015, ilg_flownet_2016, sun_pwc-net_2018, Ranjan2017, Hui2018}. These models predict pixel-precise velocity maps. The \emph{velocity map} (Figure \ref{fig:flow_map}) is a map which predict per pixel of the frame the amount of movement to another location. In equation \ref{eq:flow_basis}, $V_t(p)$ shows the velocity map as a difference between the location of the pixel in the current frame ($p$) and the location of this pixel in the next frame ($N_t(p)$).

\begin{equation}
\label{eq:flow_basis}
V_t(p) = N_t(p) - \begin{bmatrix} x_{p} \\ y_{p} \end{bmatrix}
\end{equation}

Creating a real world dataset that utilizes the power of pixel-wise flow estimation is very hard \cite{Dosovitskiy2015}. There are no real world devices which could capture both video and create pixel perfect ground-truths to train the flow estimation models on. Most of the flow estimation benchmarks are therefore generated videos. Computer 3D-engines make it possible to generate pixel-perfect flow estimation based on the generated videos in the engine.

However there is a large gap in domain and scene between the generated datasets and real world applications \cite{Liu2008}. Recent supervised papers \cite{Dosovitskiy2015, sun_pwc-net_2018} tend to overfit on these datasets and therefore perform rather poor on real world applications. One promising direction is unsupervised learning \cite{Yu2016, Janai2018, liu_ddflow_2019, liu_selflow_2019}. Early papers only predicted non-occluded pixels \cite{Yu2016, Janai2018}, but recent papers use methods to estimate occluded pixels as well \cite{liu_ddflow_2019, liu_selflow_2019}. Further details about these methods in related work.



\section{Line of Interest}
\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{images/background_LOI_kopie}
\caption{Example of LOI, red: LOI, blue: LOI area}
\label{fig:loi_example}
\end{figure}

Line of Interest is very similar to Region of Interest. Where Region of Interest is the interest of the amount of people inside the ROI, the Line of Interest is the focus on the amount of pedestrians that cross the specified line during a certain timeframe. This LOI is defined as a single line between two points $p_1$ and $p_2$ (Top and bottom point in figure \ref{fig:loi_example})

With the Line of Interest problem the goal is to give the amount of pedestrians crossing of each side given a set of frames (a pre-captured video or video stream). The output of the prediction should give two numbers $c_1$ and $c_2$ which are the amount of pedestrians crossing from each side.

Only a handful of papers are published about Line of Interest. In the earlier papers \cite{ma_counting_2016, cao_large_2015}, slicing was a widely used approach to estimate the Line of Interest. With slicing a small area, called the LOI area (Blue area in figure \ref{fig:loi_example}), is taken around the LOI. Over a set of consecutive frames each slice of the frame was taken and stitched together into a single image. On the images slow walking pedestrians appear rather wide and fast walking pedestrians shallow. By counting the amount of pedestrians present on the stitched image, the total amount of pedestrians crossing the line can be counted.

The area is defined by all the pixels that have a maximum distance to the LOI of $d$ and can be projected on the LOI. When projected, the pixels fall between $p_1$ and $p_2$.

Recent papers discard this method \cite{leibe_crossing-line_2016, zheng_cross-line_2019}, because it makes it hard to track pedestrian with different speeds and walking in different directions give artifacts which make it hard to track those pedestrians \cite{leibe_crossing-line_2016}. The slicing method is replaced with an actual frame by frame prediction method. Using two consecutive frames the amount of pedestrians crossing the line is measured. These newer methods predict both location and direction of the pedestrian.

In \cite{leibe_crossing-line_2016} both density map and velocity map are predicted by a unified network and merged together to obtain the line crossing counts. The unified model is based on FlowNetSimple \cite{Dosovitskiy2015} with an extra output layer to predict the density map. The whole network is trained in a supervised manner. For the line crossing they use the next formulas, where formula \ref{eq:zhao_sum} is the crossing for each video.
\begin{equation}
    C^{(t)}_{1} = \sum_{p \in R_{1}}\textbf{1}(v^{(t)}_{1}(p)\ge d(p,p_b)) \cdot \mathcal{D}^{(t)}(p),
\end{equation}
\begin{equation}
    C^{(t)}_{2} = \sum_{p \in R_{2}}\textbf{1}(v^{(t)}_{2}(p)\ge d(p,p_b)) \cdot \mathcal{D}^{(t)}(p),
\end{equation}
\begin{equation}
c_{1}=\sum_{\{t \mid t \in T\}} C_{1, t}, \quad c_{2}=\sum_{\{t \mid t \in T\}} C_{2, t}
\label{eq:zhao_sum}
\end{equation}
\todo{Add extra information of the symbols}


In \cite{zheng_cross-line_2019} a fast non-CNN based method is proposed based on a SVM, linear regression and the Lucas-Kanade optical flow tracker. This is much faster due to the reduction of complexity, but lacks the flexibility of a Neural Network and has difficulties with denser areas.

It uses the idea of \cite{leibe_crossing-line_2016} to discard the slicing method and uses pair-wise prediction and uses the same method to merge density and velocity. Because the methods used in \cite{zheng_cross-line_2019} are not on a pixel-level, a method is proposed to bin on a region-level. In equation \ref{eq:zheng_region_vel} a single velocity $v_{t,r}$ is calculated with a weighted average over all moving keypoints inside the region.

\begin{equation}
	v_{t,r} = \frac{\sum_p w_r(p) \cdot v^{(t)}_{towards}(p)}{\sum_p w_r(p)}
	\label{eq:zheng_region_vel}
\end{equation}

Preliminary results show that the binning on a region-level is not improving the Neural Network models to increase accuracy. However by introducing smoothing in formula \ref{eq:zhao_sum} performance increases, this is why in the method an updated line crossing formula is used.

